{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<div style=\"width:100%; aspect-ratio:16/9;\">\n",
    "  <img src=\"../img/welcome.png\" alt=\"img\" style=\"width:100%; height:auto; border-radius:8px;\">\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ **Problem Statement**\n",
    "\n",
    "Build a **scalable data processing pipeline** using PySpark to analyze flight delays across the United States.  \n",
    "The objective is to simulate a real-world data engineering workflow involving:\n",
    "\n",
    "- **Data ingestion**\n",
    "- **Data cleaning**\n",
    "- **Data transformation and enrichment**\n",
    "- **Data analysis** (using both DataFrame and SQL APIs)\n",
    "- **Output delivery**\n",
    "\n",
    "I will work with a publicly available dataset and execute all tasks in a local development environment.  \n",
    "This project is designed to:\n",
    "\n",
    "- Assess and improve my proficiency in PySpark\n",
    "- Practice efficient data processing techniques\n",
    "- Integrate with external storage systems (e.g., AWS S3)\n",
    "- Apply proper version control and documentation\n",
    "\n",
    "> ‚úàÔ∏è **My mission:**  \n",
    "> Uncover insights about flight delays and cancellations in the U.S. for 2015, and answer some key questions:  \n",
    ">Extract more significant insights from the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ´ **About the Dataset**\n",
    "\n",
    "---\n",
    "\n",
    "The **U.S. Department of Transportation's (DOT) Bureau of Transportation Statistics** tracks the on-time performance of domestic flights operated by large air carriers.\n",
    "\n",
    "Summary information on the number of **on-time, delayed, canceled, and diverted flights** is published in DOT's monthly *Air Travel Consumer Report* and is included in this dataset of **2015 flight delays and cancellations**.\n",
    "\n",
    "> üìä This dataset provides a comprehensive view of flight performance across the United States, enabling analysis of delays, cancellations, and operational patterns for the year 2015.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìö **Data Dictionary**\n",
    "\n",
    "---\n",
    "\n",
    "##### **1. `airlines.csv`**\n",
    "\n",
    "| Column      | Description                              |\n",
    "|-------------|------------------------------------------|\n",
    "| `IATA_CODE` | Code that uniquely identifies an airline |\n",
    "| `AIRLINE`   | Name of the airline                     |\n",
    "\n",
    "---\n",
    "\n",
    "##### **2. `airports.csv`**\n",
    "\n",
    "| Column      | Description                                 |\n",
    "|-------------|---------------------------------------------|\n",
    "| `IATA_CODE` | Code that uniquely identifies an airport    |\n",
    "| `AIRPORT`   | Name of the airport                        |\n",
    "| `CITY`      | City where the airport is located          |\n",
    "| `STATE`     | State where the airport is located         |\n",
    "| `COUNTRY`   | Country where the airport is located       |\n",
    "| `LATITUDE`  | Latitude of the airport                    |\n",
    "| `LONGITUDE` | Longitude of the airport                   |\n",
    "\n",
    "---\n",
    "\n",
    "##### **3. `flights.csv`**\n",
    "\n",
    "| Column                | Description                                                                 |\n",
    "|-----------------------|-----------------------------------------------------------------------------|\n",
    "| `YEAR`                | Year of the flight                                                          |\n",
    "| `MONTH`               | Month of the flight                                                         |\n",
    "| `DAY`                 | Day of the flight                                                           |\n",
    "| `DAY_OF_WEEK`         | Day of the week of flight                                                   |\n",
    "| `AIRLINE`             | Name of the airline                                                         |\n",
    "| `FLIGHT_NUMBER`       | Unique identifier for the flight                                            |\n",
    "| `TAIL_NUMBER`         | Unique identifier for the aircraft                                          |\n",
    "| `ORIGIN_AIRPORT`      | Airport code of the starting airport                                       |\n",
    "| `DESTINATION_AIRPORT` | Airport code of the destination airport                                    |\n",
    "| `SCHEDULED_DEPARTURE` | Scheduled departure time of the flight                                      |\n",
    "| `DEPARTURE_TIME`      | Actual departure time of the flight                                         |\n",
    "| `DEPARTURE_DELAY`     | Delay in departure of the flight                                            |\n",
    "| `TAXI_OUT`            | Time elapsed between gate departure and wheels off                          |\n",
    "| `WHEELS_OFF`          | Time when the aircraft's wheels leave the ground                            |\n",
    "| `SCHEDULED_TIME`      | Planned time amount needed for the flight trip                              |\n",
    "| `ELAPSED_TIME`        | AIR_TIME + TAXI_IN + TAXI_OUT                                               |\n",
    "| `AIR_TIME`            | Time between wheels_off and wheels_on                                       |\n",
    "| `DISTANCE`            | Distance between two airports                                               |\n",
    "| `WHEELS_ON`           | Time when the wheels of the aircraft touch the ground                       |\n",
    "| `TAXI_IN`             | Time elapsed between wheels-on and gate arrival at the destination airport  |\n",
    "| `SCHEDULED_ARRIVAL`   | Planned arrival time of the flight                                          |\n",
    "| `ARRIVAL_TIME`        | WHEELS_ON + TAXI_IN                                                         |\n",
    "| `ARRIVAL_DELAY`       | ARRIVAL_TIME minus SCHEDULED_ARRIVAL                                        |\n",
    "| `CANCELLED`           | Flight Cancelled (1 = cancelled)                                            |\n",
    "| `DIVERTED`            | Aircraft landed at an unscheduled airport                                   |\n",
    "| `CANCELLATION_REASON` | Reason for cancellation (A = carrier, B = weather, C = national air system, D = security) |\n",
    "| `AIR_SYSTEM_DELAY`    | Delay due to the national air system                                        |\n",
    "| `SECURITY_DELAY`      | Delay due to security                                                       |\n",
    "| `AIRLINE_DELAY`       | Delay due to the airline                                                    |\n",
    "| `LATE_AIRCRAFT_DELAY` | Delay due to the aircraft                                                   |\n",
    "| `WEATHER_DELAY`       | Delay due to the weather                                                    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù **Let's start the analysis**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating neccessary imports\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  ‚è≥ **Loading the data and creating spark session**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/new-user/Documents/PySpark-EDA-Flights-Data/myvenv/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/new-user/.ivy2/cache\n",
      "The jars for the packages stored in: /home/new-user/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-2c6f8d73-ee2a-4520-9e2d-65d40294b8ab;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.3.2 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.1026 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      ":: resolution report :: resolve 170ms :: artifacts dl 6ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.1026 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.3.2 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-2c6f8d73-ee2a-4520-9e2d-65d40294b8ab\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/5ms)\n",
      "25/05/11 18:35:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "#lets start the spark session with the data ingestion module functions and view some data\n",
    "\n",
    "from src.data_ingestion import get_spark_session, load_dataframes\n",
    "\n",
    "spark , s3_bucket = get_spark_session()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")  # Only show errors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://akash-data25:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Flight Data</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x729ee878c2c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚Äçüî¨ **Basic Data Exploration**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+\n",
      "|YEAR|MONTH|DAY|DAY_OF_WEEK|AIRLINE|FLIGHT_NUMBER|TAIL_NUMBER|ORIGIN_AIRPORT|DESTINATION_AIRPORT|SCHEDULED_DEPARTURE|DEPARTURE_TIME|DEPARTURE_DELAY|TAXI_OUT|WHEELS_OFF|SCHEDULED_TIME|ELAPSED_TIME|AIR_TIME|DISTANCE|WHEELS_ON|TAXI_IN|SCHEDULED_ARRIVAL|ARRIVAL_TIME|ARRIVAL_DELAY|DIVERTED|CANCELLED|CANCELLATION_REASON|AIR_SYSTEM_DELAY|SECURITY_DELAY|AIRLINE_DELAY|LATE_AIRCRAFT_DELAY|WEATHER_DELAY|\n",
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+\n",
      "|2015|    1|  1|          4|     AS|           98|     N407AS|           ANC|                SEA|                  5|          2354|            -11|      21|        15|           205|         194|     169|    1448|      404|      4|              430|         408|          -22|       0|        0|               NULL|            NULL|          NULL|         NULL|               NULL|         NULL|\n",
      "|2015|    1|  1|          4|     AA|         2336|     N3KUAA|           LAX|                PBI|                 10|             2|             -8|      12|        14|           280|         279|     263|    2330|      737|      4|              750|         741|           -9|       0|        0|               NULL|            NULL|          NULL|         NULL|               NULL|         NULL|\n",
      "|2015|    1|  1|          4|     US|          840|     N171US|           SFO|                CLT|                 20|            18|             -2|      16|        34|           286|         293|     266|    2296|      800|     11|              806|         811|            5|       0|        0|               NULL|            NULL|          NULL|         NULL|               NULL|         NULL|\n",
      "|2015|    1|  1|          4|     AA|          258|     N3HYAA|           LAX|                MIA|                 20|            15|             -5|      15|        30|           285|         281|     258|    2342|      748|      8|              805|         756|           -9|       0|        0|               NULL|            NULL|          NULL|         NULL|               NULL|         NULL|\n",
      "|2015|    1|  1|          4|     AS|          135|     N527AS|           SEA|                ANC|                 25|            24|             -1|      11|        35|           235|         215|     199|    1448|      254|      5|              320|         259|          -21|       0|        0|               NULL|            NULL|          NULL|         NULL|               NULL|         NULL|\n",
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---------+--------------------+\n",
      "|IATA_CODE|             AIRLINE|\n",
      "+---------+--------------------+\n",
      "|       UA|United Air Lines ...|\n",
      "|       AA|American Airlines...|\n",
      "|       US|     US Airways Inc.|\n",
      "|       F9|Frontier Airlines...|\n",
      "|       B6|     JetBlue Airways|\n",
      "+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---------+--------------------+-----------+-----+-------+--------+----------+\n",
      "|IATA_CODE|             AIRPORT|       CITY|STATE|COUNTRY|LATITUDE| LONGITUDE|\n",
      "+---------+--------------------+-----------+-----+-------+--------+----------+\n",
      "|      ABE|Lehigh Valley Int...|  Allentown|   PA|    USA|40.65236|  -75.4404|\n",
      "|      ABI|Abilene Regional ...|    Abilene|   TX|    USA|32.41132|  -99.6819|\n",
      "|      ABQ|Albuquerque Inter...|Albuquerque|   NM|    USA|35.04022|-106.60919|\n",
      "|      ABR|Aberdeen Regional...|   Aberdeen|   SD|    USA|45.44906| -98.42183|\n",
      "|      ABY|Southwest Georgia...|     Albany|   GA|    USA|31.53552| -84.19447|\n",
      "+---------+--------------------+-----------+-----+-------+--------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#lets view the data\n",
    "flights_df, airlines_df, airports_df = load_dataframes(spark, s3_bucket)\n",
    "\n",
    "flights_df.show(5)\n",
    "airlines_df.show(5)\n",
    "airports_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- YEAR: integer (nullable = true)\n",
      " |-- MONTH: integer (nullable = true)\n",
      " |-- DAY: integer (nullable = true)\n",
      " |-- DAY_OF_WEEK: integer (nullable = true)\n",
      " |-- AIRLINE: string (nullable = true)\n",
      " |-- FLIGHT_NUMBER: integer (nullable = true)\n",
      " |-- TAIL_NUMBER: string (nullable = true)\n",
      " |-- ORIGIN_AIRPORT: string (nullable = true)\n",
      " |-- DESTINATION_AIRPORT: string (nullable = true)\n",
      " |-- SCHEDULED_DEPARTURE: integer (nullable = true)\n",
      " |-- DEPARTURE_TIME: integer (nullable = true)\n",
      " |-- DEPARTURE_DELAY: integer (nullable = true)\n",
      " |-- TAXI_OUT: integer (nullable = true)\n",
      " |-- WHEELS_OFF: integer (nullable = true)\n",
      " |-- SCHEDULED_TIME: integer (nullable = true)\n",
      " |-- ELAPSED_TIME: integer (nullable = true)\n",
      " |-- AIR_TIME: integer (nullable = true)\n",
      " |-- DISTANCE: integer (nullable = true)\n",
      " |-- WHEELS_ON: integer (nullable = true)\n",
      " |-- TAXI_IN: integer (nullable = true)\n",
      " |-- SCHEDULED_ARRIVAL: integer (nullable = true)\n",
      " |-- ARRIVAL_TIME: integer (nullable = true)\n",
      " |-- ARRIVAL_DELAY: integer (nullable = true)\n",
      " |-- DIVERTED: integer (nullable = true)\n",
      " |-- CANCELLED: integer (nullable = true)\n",
      " |-- CANCELLATION_REASON: string (nullable = true)\n",
      " |-- AIR_SYSTEM_DELAY: integer (nullable = true)\n",
      " |-- SECURITY_DELAY: integer (nullable = true)\n",
      " |-- AIRLINE_DELAY: integer (nullable = true)\n",
      " |-- LATE_AIRCRAFT_DELAY: integer (nullable = true)\n",
      " |-- WEATHER_DELAY: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#lets inspect the schema of the data\n",
    "flights_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- IATA_CODE: string (nullable = true)\n",
      " |-- AIRLINE: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airlines_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- IATA_CODE: string (nullable = true)\n",
      " |-- AIRPORT: string (nullable = true)\n",
      " |-- CITY: string (nullable = true)\n",
      " |-- STATE: string (nullable = true)\n",
      " |-- COUNTRY: string (nullable = true)\n",
      " |-- LATITUDE: double (nullable = true)\n",
      " |-- LONGITUDE: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airports_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:===============================================>           (4 + 1) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+-----------------+-----------------+-------+------------------+-----------+--------------+-------------------+-------------------+------------------+------------------+------------------+------------------+-----------------+------------------+------------------+-----------------+-----------------+-----------------+------------------+-----------------+------------------+--------------------+--------------------+-------------------+------------------+-------------------+------------------+-------------------+------------------+\n",
      "|summary|  YEAR| MONTH|              DAY|      DAY_OF_WEEK|AIRLINE|     FLIGHT_NUMBER|TAIL_NUMBER|ORIGIN_AIRPORT|DESTINATION_AIRPORT|SCHEDULED_DEPARTURE|    DEPARTURE_TIME|   DEPARTURE_DELAY|          TAXI_OUT|        WHEELS_OFF|   SCHEDULED_TIME|      ELAPSED_TIME|          AIR_TIME|         DISTANCE|        WHEELS_ON|          TAXI_IN| SCHEDULED_ARRIVAL|     ARRIVAL_TIME|     ARRIVAL_DELAY|            DIVERTED|           CANCELLED|CANCELLATION_REASON|  AIR_SYSTEM_DELAY|     SECURITY_DELAY|     AIRLINE_DELAY|LATE_AIRCRAFT_DELAY|     WEATHER_DELAY|\n",
      "+-------+------+------+-----------------+-----------------+-------+------------------+-----------+--------------+-------------------+-------------------+------------------+------------------+------------------+------------------+-----------------+------------------+------------------+-----------------+-----------------+-----------------+------------------+-----------------+------------------+--------------------+--------------------+-------------------+------------------+-------------------+------------------+-------------------+------------------+\n",
      "|  count|180000|180000|           180000|           180000| 180000|            180000|     179623|        180000|             180000|             180000|            175423|            175423|            175280|            175280|           180000|            174743|            174743|           180000|           175083|           175083|            180000|           175083|            174743|              180000|              180000|               4767|             54714|              54714|             54714|              54714|             54714|\n",
      "|   mean|2015.0|   1.0|          6.29075|4.293644444444444|   NULL|2261.1365333333333|       NULL|          NULL|               NULL| 1315.3495555555555|1333.4611481960746|17.490825034345555|16.930870607028755|1356.0265575079873|141.6366111111111|140.29058674739474|115.29652117681395|816.8442722222222|1472.828258597351|8.072588429487729|1495.2400555555555|1477.894958391163|15.132772128211144|0.002722222222222...|0.026483333333333334|               NULL|13.952736045619037|0.06555908908140512|17.923968271374786|  25.54717257009175| 3.354936579303286|\n",
      "| stddev|   0.0|   0.0|3.339460827030334|2.017736906793616|   NULL|1810.9377722761496|       NULL|          NULL|               NULL|  469.5759677834299| 487.4647732969832| 44.09323478704831|10.367970542911324| 488.2240251852685|75.52442830237288|  75.3261153229362|  73.1283422640862|602.8892822589189|514.8648838971062|7.601202406706585|486.27506299667857|519.8104451732876|47.097790948937565| 0.05210399994977583|  0.1605680840728672|               NULL| 26.95628373673837| 1.6322459297317686|43.012009563811304|  43.06338571049488|19.996822774895982|\n",
      "|    min|  2015|     1|                1|                1|     AA|                 1|     N001AA|           ABE|                ABE|                  5|                 1|               -42|                 1|                 1|               23|                17|                 8|               31|                1|                1|                 1|                1|               -74|                   0|                   0|                  A|                 0|                  0|                 0|                  0|                 0|\n",
      "|    max|  2015|     1|               12|                7|     WN|              7438|     N9EAMQ|           YUM|                YUM|               2359|              2400|              1450|               176|              2400|              718|               724|               676|             4983|             2400|              179|              2359|             2400|              1444|                   1|                   1|                  D|               824|                107|              1444|                891|               938|\n",
      "+-------+------+------+-----------------+-----------------+-------+------------------+-----------+--------------+-------------------+-------------------+------------------+------------------+------------------+------------------+-----------------+------------------+------------------+-----------------+-----------------+-----------------+------------------+-----------------+------------------+--------------------+--------------------+-------------------+------------------+-------------------+------------------+-------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#lets view the summary of the data\n",
    "flights_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------------------+\n",
      "|summary|IATA_CODE|             AIRLINE|\n",
      "+-------+---------+--------------------+\n",
      "|  count|       14|                  14|\n",
      "|   mean|     NULL|                NULL|\n",
      "| stddev|     NULL|                NULL|\n",
      "|    min|       AA|Alaska Airlines Inc.|\n",
      "|    max|       WN|      Virgin America|\n",
      "+-------+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airlines_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------------------+--------+-----+-------+------------------+------------------+\n",
      "|summary|IATA_CODE|             AIRPORT|    CITY|STATE|COUNTRY|          LATITUDE|         LONGITUDE|\n",
      "+-------+---------+--------------------+--------+-----+-------+------------------+------------------+\n",
      "|  count|      322|                 322|     322|  322|    322|               319|               319|\n",
      "|   mean|     NULL|                NULL|    NULL| NULL|   NULL|38.981243918495295|-98.37896445141064|\n",
      "| stddev|     NULL|                NULL|    NULL| NULL|   NULL| 8.616735581018041|21.523492046498102|\n",
      "|    min|      ABE|Aberdeen Regional...|Aberdeen|   AK|    USA|          13.48345|        -176.64603|\n",
      "|    max|      YUM|Yuma Internationa...|    Yuma|   WY|    USA|          71.28545|         -64.79856|\n",
      "+-------+---------+--------------------+--------+-----+-------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airports_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üßΩ  **Cleaning the data**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns to drop (> 20% nulls): []\n",
      "Columns to drop rows for (<20% nulls): ['IATA_CODE', 'AIRLINE']\n",
      "\n",
      "Dropped rows with nulls in columns: ['IATA_CODE', 'AIRLINE']\n"
     ]
    }
   ],
   "source": [
    "#lets treat the nulls in the data\n",
    "from src.data_cleaning import clean_nulls\n",
    "\n",
    "airlines_df = clean_nulls(airlines_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns to drop (> 20% nulls): []\n",
      "Columns to drop rows for (<20% nulls): ['IATA_CODE', 'AIRPORT', 'CITY', 'STATE', 'COUNTRY', 'LATITUDE', 'LONGITUDE']\n",
      "\n",
      "Dropped rows with nulls in columns: ['IATA_CODE', 'AIRPORT', 'CITY', 'STATE', 'COUNTRY', 'LATITUDE', 'LONGITUDE']\n"
     ]
    }
   ],
   "source": [
    "airports_df = clean_nulls(airports_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 144:=============================================>           (4 + 1) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns to drop (> 20% nulls): ['CANCELLATION_REASON', 'AIR_SYSTEM_DELAY', 'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY']\n",
      "Columns to drop rows for (<20% nulls): ['YEAR', 'MONTH', 'DAY', 'DAY_OF_WEEK', 'AIRLINE', 'FLIGHT_NUMBER', 'TAIL_NUMBER', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME', 'DEPARTURE_DELAY', 'TAXI_OUT', 'WHEELS_OFF', 'SCHEDULED_TIME', 'ELAPSED_TIME', 'AIR_TIME', 'DISTANCE', 'WHEELS_ON', 'TAXI_IN', 'SCHEDULED_ARRIVAL', 'ARRIVAL_TIME', 'ARRIVAL_DELAY', 'DIVERTED', 'CANCELLED']\n",
      "\n",
      "Dropped rows with nulls in columns: ['YEAR', 'MONTH', 'DAY', 'DAY_OF_WEEK', 'AIRLINE', 'FLIGHT_NUMBER', 'TAIL_NUMBER', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME', 'DEPARTURE_DELAY', 'TAXI_OUT', 'WHEELS_OFF', 'SCHEDULED_TIME', 'ELAPSED_TIME', 'AIR_TIME', 'DISTANCE', 'WHEELS_ON', 'TAXI_IN', 'SCHEDULED_ARRIVAL', 'ARRIVAL_TIME', 'ARRIVAL_DELAY', 'DIVERTED', 'CANCELLED']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "flights_df = clean_nulls(flights_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+\n",
      "|IATA_CODE|AIRLINE|\n",
      "+---------+-------+\n",
      "|        0|      0|\n",
      "+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lets check the nulls now\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "exprs = [F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in airlines_df.columns]\n",
    "airlines_df.select(exprs).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+----+-----+-------+--------+---------+\n",
      "|IATA_CODE|AIRPORT|CITY|STATE|COUNTRY|LATITUDE|LONGITUDE|\n",
      "+---------+-------+----+-----+-------+--------+---------+\n",
      "|        0|      0|   0|    0|      0|       0|        0|\n",
      "+---------+-------+----+-----+-------+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "exprs = [F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in airports_df.columns]\n",
    "airports_df.select(exprs).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 153:=============================================>           (4 + 1) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+\n",
      "|YEAR|MONTH|DAY|DAY_OF_WEEK|AIRLINE|FLIGHT_NUMBER|TAIL_NUMBER|ORIGIN_AIRPORT|DESTINATION_AIRPORT|SCHEDULED_DEPARTURE|DEPARTURE_TIME|DEPARTURE_DELAY|TAXI_OUT|WHEELS_OFF|SCHEDULED_TIME|ELAPSED_TIME|AIR_TIME|DISTANCE|WHEELS_ON|TAXI_IN|SCHEDULED_ARRIVAL|ARRIVAL_TIME|ARRIVAL_DELAY|DIVERTED|CANCELLED|\n",
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+\n",
      "|   0|    0|  0|          0|      0|            0|          0|             0|                  0|                  0|             0|              0|       0|         0|             0|           0|       0|       0|        0|      0|                0|           0|            0|       0|        0|\n",
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "exprs = [F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in flights_df.columns]\n",
    "flights_df.select(exprs).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### üí° Some observations:-\n",
    " * We went ahead with the strategy of dropping the nulls in the data, which are less than 20% of the total data in the specific columns instead of imputation because flights data is dependent on time and time is a critical factor in the data which is not easy to impute.\n",
    " \n",
    " * We also dropped columns with greater than 20% of nulls ,  as it will affect the analysis and the results.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üîÑ **Removing duplicates**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates removed: 0\n"
     ]
    }
   ],
   "source": [
    "#lets remove the duplicates in the data\n",
    "\n",
    "from src.data_cleaning import remove_duplicates\n",
    "\n",
    "airlines_df = remove_duplicates(airlines_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates removed: 0\n"
     ]
    }
   ],
   "source": [
    "airports_df = remove_duplicates(airports_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 177:=============================================>           (4 + 1) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates removed: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "flights_df = remove_duplicates(flights_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### üßê Some observations:-\n",
    "\n",
    " * Viewing the flights dataframe, we can see that the time format of various columns is not correct we need to fix that.\n",
    "\n",
    " * Some columns have minutes mentioned directly instead of time in clock format.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üßë‚Äçüî¨ **Formatting the time based columns**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a function to format the time column\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "def format_time_spark(hhmm):\n",
    "    if hhmm is None:\n",
    "        return None\n",
    "    try:\n",
    "        hhmm = int(hhmm)\n",
    "        if hhmm == 2400:\n",
    "            hhmm = 0\n",
    "        hhmm_str = f\"{hhmm:04d}\"\n",
    "        hour = int(hhmm_str[:2])\n",
    "        minute = int(hhmm_str[2:])\n",
    "        return f\"{hour:02d}:{minute:02d}\"\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "#registering the udf\n",
    "format_time_udf = F.udf(format_time_spark, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_df = flights_df.withColumn(\n",
    "    \"DEPARTURE_TIME_STR\",  \n",
    "    format_time_udf(F.col(\"DEPARTURE_TIME\"))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_df = flights_df.withColumn(\n",
    "    \"ARRIVAL_TIME\",  \n",
    "    format_time_udf(F.col(\"ARRIVAL_TIME\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_df = flights_df.withColumn(\n",
    "    \"SCHEDULED_DEPARTURE\",  \n",
    "    format_time_udf(F.col(\"SCHEDULED_DEPARTURE\"))\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_df = flights_df.withColumn(\n",
    "    \"SCHEDULED_ARRIVAL\",  \n",
    "    format_time_udf(F.col(\"SCHEDULED_ARRIVAL\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 183:=============================================>           (4 + 1) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+------------------+--------+\n",
      "|YEAR|MONTH|DAY|DAY_OF_WEEK|AIRLINE|FLIGHT_NUMBER|TAIL_NUMBER|ORIGIN_AIRPORT|DESTINATION_AIRPORT|SCHEDULED_DEPARTURE|DEPARTURE_TIME|DEPARTURE_DELAY|TAXI_OUT|WHEELS_OFF|SCHEDULED_TIME|ELAPSED_TIME|AIR_TIME|DISTANCE|WHEELS_ON|TAXI_IN|SCHEDULED_ARRIVAL|ARRIVAL_TIME|ARRIVAL_DELAY|DIVERTED|CANCELLED|DEPARTURE_TIME_STR|    DATE|\n",
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+------------------+--------+\n",
      "|2015|    1|  1|          4|     DL|          978|     N693DL|           SAN|                SLC|              06:15|           611|             -4|      20|       631|           121|         115|      89|     626|      900|      6|            09:16|       09:06|          -10|       0|        0|             06:11|2015-1-1|\n",
      "|2015|    1|  1|          4|     DL|         2109|     N550NW|           SAN|                DTW|              07:05|           703|             -2|      13|       716|           259|         233|     214|    1956|     1350|      6|            14:24|       13:56|          -28|       0|        0|             07:03|2015-1-1|\n",
      "|2015|    1|  1|          4|     AA|         1482|     N3DUAA|           SFO|                DFW|              07:10|           703|             -7|      16|       719|           210|         214|     185|    1464|     1224|     13|            12:40|       12:37|           -3|       0|        0|             07:03|2015-1-1|\n",
      "|2015|    1|  1|          4|     EV|         5242|     N707EV|           CLE|                LGA|              07:15|           959|            164|      12|      1011|           106|          75|      59|     419|     1110|      4|            09:01|       11:14|          133|       0|        0|             09:59|2015-1-1|\n",
      "|2015|    1|  1|          4|     OO|         4836|     N549CA|           LAS|                SLC|              08:00|           755|             -5|      15|       810|            85|          89|      66|     368|     1016|      8|            10:25|       10:24|           -1|       0|        0|             07:55|2015-1-1|\n",
      "|2015|    1|  1|          4|     OO|         6389|     N958SW|           ORD|                TVC|              08:08|           803|             -5|      18|       821|            65|          65|      42|     224|     1003|      5|            10:13|       10:08|           -5|       0|        0|             08:03|2015-1-1|\n",
      "|2015|    1|  1|          4|     EV|         4525|     N27190|           OMA|                IAH|              09:46|           946|              0|      19|      1005|           143|         159|     127|     781|     1212|     13|            12:09|       12:25|           16|       0|        0|             09:46|2015-1-1|\n",
      "|2015|    1|  1|          4|     MQ|         3016|     N645MQ|           PNS|                DFW|              09:50|           945|             -5|      15|      1000|           125|         126|     106|     604|     1146|      5|            11:55|       11:51|           -4|       0|        0|             09:45|2015-1-1|\n",
      "|2015|    1|  1|          4|     WN|         1952|     N8640D|           PHX|                IND|              10:10|          1012|              2|      21|      1033|           195|         183|     157|    1488|     1510|      5|            15:25|       15:15|          -10|       0|        0|             10:12|2015-1-1|\n",
      "|2015|    1|  1|          4|     F9|          934|     N938FR|           CVG|                TTN|              10:27|          1026|             -1|       9|      1035|            98|          81|      67|     532|     1142|      5|            12:05|       11:47|          -18|       0|        0|             10:26|2015-1-1|\n",
      "|2015|    1|  1|          4|     WN|          810|     N961WN|           RDU|                TPA|              10:35|          1031|             -4|      13|      1044|           110|         113|      95|     587|     1219|      5|            12:25|       12:24|           -1|       0|        0|             10:31|2015-1-1|\n",
      "|2015|    1|  1|          4|     EV|         4672|     N11193|           MEM|                EWR|              10:53|          1056|              3|      15|      1111|           158|         140|     118|     946|     1409|      7|            14:31|       14:16|          -15|       0|        0|             10:56|2015-1-1|\n",
      "|2015|    1|  1|          4|     OO|         4774|     N807SK|           SLC|                PSC|              11:11|          1104|             -7|      23|      1127|           113|         104|      76|     521|     1143|      5|            12:04|       11:48|          -16|       0|        0|             11:04|2015-1-1|\n",
      "|2015|    1|  1|          4|     UA|         1491|     N76254|           DEN|                IAD|              11:20|          1227|             67|      10|      1237|           194|         168|     154|    1452|     1711|      4|            16:34|       17:15|           41|       0|        0|             12:27|2015-1-1|\n",
      "|2015|    1|  1|          4|     WN|          768|     N8319F|           MCO|                BWI|              11:25|          1122|             -3|       8|      1130|           130|         115|     103|     787|     1313|      4|            13:35|       13:17|          -18|       0|        0|             11:22|2015-1-1|\n",
      "|2015|    1|  1|          4|     EV|         2523|     N908EV|           SHV|                DFW|              12:25|          1339|             74|       7|      1346|            60|          60|      37|     190|     1423|     16|            13:25|       14:39|           74|       0|        0|             13:39|2015-1-1|\n",
      "|2015|    1|  1|          4|     EV|         5664|     N14993|           IAH|                BTR|              12:50|          1250|              0|      17|      1307|            61|          62|      41|     253|     1348|      4|            13:51|       13:52|            1|       0|        0|             12:50|2015-1-1|\n",
      "|2015|    1|  1|          4|     UA|          490|     N834UA|           JAC|                DEN|              13:39|          1338|             -1|      11|      1349|            85|          78|      62|     406|     1451|      5|            15:04|       14:56|           -8|       0|        0|             13:38|2015-1-1|\n",
      "|2015|    1|  1|          4|     AA|         1627|     N4XHAA|           FAT|                DFW|              13:50|          1352|              2|       9|      1401|           190|         189|     167|    1313|     1848|     13|            19:00|       19:01|            1|       0|        0|             13:52|2015-1-1|\n",
      "|2015|    1|  1|          4|     EV|         6179|     N21144|           DEN|                ISN|              13:55|          1513|             78|      11|      1524|           110|         103|      86|     576|     1750|      6|            16:45|       17:56|           71|       0|        0|             15:13|2015-1-1|\n",
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#lets create a date column combining the year, month, day\n",
    "flights_df = flights_df.withColumn(\n",
    "    \"DATE\",  \n",
    "    F.concat_ws(\"-\", F.col(\"YEAR\"), F.col(\"MONTH\"), F.col(\"DAY\"))\n",
    ")\n",
    "flights_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "def create_flight_datetime(df, date_col, time_col, new_col):\n",
    "    \"\"\"\n",
    "    Combines a date column (yyyy-M-d or yyyy-MM-dd) and a time string column (HH:mm) into a timestamp column.\n",
    "    Pads the date as needed.\n",
    "    \"\"\"\n",
    "    # 1. Pad the date\n",
    "    df = df.withColumn(\"PADDED_DATE\",\n",
    "        F.concat_ws(\"-\",\n",
    "            F.split(F.col(date_col), \"-\")[0],\n",
    "            F.lpad(F.split(F.col(date_col), \"-\")[1], 2, \"0\"),\n",
    "            F.lpad(F.split(F.col(date_col), \"-\")[2], 2, \"0\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 2. Combine padded date and time\n",
    "    df = df.withColumn(\n",
    "        \"DATETIME_STR\",\n",
    "        F.when(\n",
    "            F.col(\"PADDED_DATE\").isNotNull() & F.col(time_col).isNotNull(),\n",
    "            F.concat_ws(\" \", F.col(\"PADDED_DATE\"), F.col(time_col))\n",
    "        ).otherwise(None)\n",
    "    )\n",
    "\n",
    "    # 3. Convert to timestamp\n",
    "    df = df.withColumn(\n",
    "        new_col,\n",
    "        F.to_timestamp(F.col(\"DATETIME_STR\"), \"yyyy-MM-dd HH:mm\")\n",
    "    )\n",
    "\n",
    "    # 4. Drop intermediate columns\n",
    "    df = df.drop(\"PADDED_DATE\", \"DATETIME_STR\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_df = create_flight_datetime(flights_df, \"DATE\", \"DEPARTURE_TIME_STR\", \"DEPARTURE_DATE_TIME\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_df = create_flight_datetime(flights_df, \"DATE\", \"ARRIVAL_TIME\", \"ARRIVAL_DATE_TIME\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### üß† Some observations:-\n",
    "\n",
    " * The departure delay column wherever negative means that the flight departed early.\n",
    " \n",
    " * Similarly for  arrival time, if it is negative, it means that the flight arrived early."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚ú® **Data Enrichment**\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div align=\"center\">\n",
    "<div style=\"width:450px; aspect-ratio:16/9;\">\n",
    "  <img src=\"../img/brodcast.jpeg\" alt=\"brodcast\" style=\"width:100%; height:auto; border-radius:8px;\">\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# added a delay category column to the dataframe\n",
    "from src.data_enrichment import add_delay_category\n",
    "\n",
    "flights_df = add_delay_category(flights_df, delay_col=\"ARRIVAL_DELAY\", new_col=\"DELAY_CATEGORY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 186:==================================>                      (3 + 2) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+-----------+------------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+------------------+--------+-------------------+-------------------+--------------+--------------------+\n",
      "|YEAR|MONTH|DAY|DAY_OF_WEEK|AIRLINE_CODE|FLIGHT_NUMBER|TAIL_NUMBER|ORIGIN_AIRPORT|DESTINATION_AIRPORT|SCHEDULED_DEPARTURE|DEPARTURE_TIME|DEPARTURE_DELAY|TAXI_OUT|WHEELS_OFF|SCHEDULED_TIME|ELAPSED_TIME|AIR_TIME|DISTANCE|WHEELS_ON|TAXI_IN|SCHEDULED_ARRIVAL|ARRIVAL_TIME|ARRIVAL_DELAY|DIVERTED|CANCELLED|DEPARTURE_TIME_STR|    DATE|DEPARTURE_DATE_TIME|  ARRIVAL_DATE_TIME|DELAY_CATEGORY|        AIRLINE_NAME|\n",
      "+----+-----+---+-----------+------------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+------------------+--------+-------------------+-------------------+--------------+--------------------+\n",
      "|2015|    1|  1|          4|          DL|          978|     N693DL|           SAN|                SLC|              06:15|           611|             -4|      20|       631|           121|         115|      89|     626|      900|      6|            09:16|       09:06|          -10|       0|        0|             06:11|2015-1-1|2015-01-01 06:11:00|2015-01-01 09:06:00|       On-Time|Delta Air Lines Inc.|\n",
      "|2015|    1|  1|          4|          DL|         2109|     N550NW|           SAN|                DTW|              07:05|           703|             -2|      13|       716|           259|         233|     214|    1956|     1350|      6|            14:24|       13:56|          -28|       0|        0|             07:03|2015-1-1|2015-01-01 07:03:00|2015-01-01 13:56:00|       On-Time|Delta Air Lines Inc.|\n",
      "|2015|    1|  1|          4|          AA|         1482|     N3DUAA|           SFO|                DFW|              07:10|           703|             -7|      16|       719|           210|         214|     185|    1464|     1224|     13|            12:40|       12:37|           -3|       0|        0|             07:03|2015-1-1|2015-01-01 07:03:00|2015-01-01 12:37:00|       On-Time|American Airlines...|\n",
      "|2015|    1|  1|          4|          EV|         5242|     N707EV|           CLE|                LGA|              07:15|           959|            164|      12|      1011|           106|          75|      59|     419|     1110|      4|            09:01|       11:14|          133|       0|        0|             09:59|2015-1-1|2015-01-01 09:59:00|2015-01-01 11:14:00|    Long Delay|Atlantic Southeas...|\n",
      "|2015|    1|  1|          4|          OO|         4836|     N549CA|           LAS|                SLC|              08:00|           755|             -5|      15|       810|            85|          89|      66|     368|     1016|      8|            10:25|       10:24|           -1|       0|        0|             07:55|2015-1-1|2015-01-01 07:55:00|2015-01-01 10:24:00|       On-Time|Skywest Airlines ...|\n",
      "+----+-----+---+-----------+------------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+------------------+--------+-------------------+-------------------+--------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import broadcast\n",
    "\n",
    "# 1. Rename in airlines_df\n",
    "airlines_df = airlines_df.withColumnRenamed(\"AIRLINE\", \"AIRLINE_NAME\")\n",
    "\n",
    "# 2. Join\n",
    "flights_df_joined = flights_df.join(\n",
    "    broadcast(airlines_df),\n",
    "    flights_df.AIRLINE == airlines_df.IATA_CODE,\n",
    "    how=\"left\"\n",
    ").drop(airlines_df.IATA_CODE)\n",
    "\n",
    "flights_df_joined = flights_df_joined.withColumnRenamed(\"AIRLINE\", \"AIRLINE_CODE\")\n",
    "\n",
    "flights_df_joined.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# . Join with airports for origin airport details\n",
    "flights_with_origin = flights_df_joined.join(\n",
    "    broadcast(airports_df),\n",
    "    flights_df_joined.ORIGIN_AIRPORT == airports_df.IATA_CODE,\n",
    "    how=\"left\"\n",
    ").withColumnRenamed(\"AIRPORT\", \"ORIGIN_AIRPORT_NAME\") \\\n",
    " .withColumnRenamed(\"CITY\", \"ORIGIN_CITY\") \\\n",
    " .withColumnRenamed(\"STATE\", \"ORIGIN_STATE\") \\\n",
    " .withColumnRenamed(\"COUNTRY\", \"ORIGIN_COUNTRY\") \\\n",
    " .withColumnRenamed(\"LATITUDE\", \"ORIGIN_LATITUDE\") \\\n",
    " .withColumnRenamed(\"LONGITUDE\", \"ORIGIN_LONGITUDE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_with_origin = flights_with_origin.drop(\"IATA_CODE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# . Join with airports for destination airport details\n",
    "\n",
    "flights_enriched_df = flights_with_origin.join(\n",
    "    broadcast(airports_df),\n",
    "    flights_with_origin.DESTINATION_AIRPORT == airports_df.IATA_CODE,\n",
    "    how=\"left\"\n",
    ").withColumnRenamed(\"AIRPORT\", \"DESTINATION_AIRPORT_NAME\") \\\n",
    " .withColumnRenamed(\"CITY\", \"DESTINATION_CITY\") \\\n",
    " .withColumnRenamed(\"STATE\", \"DESTINATION_STATE\") \\\n",
    " .withColumnRenamed(\"COUNTRY\", \"DESTINATION_COUNTRY\") \\\n",
    " .withColumnRenamed(\"LATITUDE\", \"DESTINATION_LATITUDE\") \\\n",
    " .withColumnRenamed(\"LONGITUDE\", \"DESTINATION_LONGITUDE\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 192:==================================>                      (3 + 2) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+-----------+------------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+------------------+--------+-------------------+-------------------+--------------+--------------------+--------------------+-------------+------------+--------------+---------------+----------------+---------+------------------------+-----------------+-----------------+-------------------+--------------------+---------------------+\n",
      "|YEAR|MONTH|DAY|DAY_OF_WEEK|AIRLINE_CODE|FLIGHT_NUMBER|TAIL_NUMBER|ORIGIN_AIRPORT|DESTINATION_AIRPORT|SCHEDULED_DEPARTURE|DEPARTURE_TIME|DEPARTURE_DELAY|TAXI_OUT|WHEELS_OFF|SCHEDULED_TIME|ELAPSED_TIME|AIR_TIME|DISTANCE|WHEELS_ON|TAXI_IN|SCHEDULED_ARRIVAL|ARRIVAL_TIME|ARRIVAL_DELAY|DIVERTED|CANCELLED|DEPARTURE_TIME_STR|    DATE|DEPARTURE_DATE_TIME|  ARRIVAL_DATE_TIME|DELAY_CATEGORY|        AIRLINE_NAME| ORIGIN_AIRPORT_NAME|  ORIGIN_CITY|ORIGIN_STATE|ORIGIN_COUNTRY|ORIGIN_LATITUDE|ORIGIN_LONGITUDE|IATA_CODE|DESTINATION_AIRPORT_NAME| DESTINATION_CITY|DESTINATION_STATE|DESTINATION_COUNTRY|DESTINATION_LATITUDE|DESTINATION_LONGITUDE|\n",
      "+----+-----+---+-----------+------------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+------------------+--------+-------------------+-------------------+--------------+--------------------+--------------------+-------------+------------+--------------+---------------+----------------+---------+------------------------+-----------------+-----------------+-------------------+--------------------+---------------------+\n",
      "|2015|    1|  1|          4|          DL|          978|     N693DL|           SAN|                SLC|              06:15|           611|             -4|      20|       631|           121|         115|      89|     626|      900|      6|            09:16|       09:06|          -10|       0|        0|             06:11|2015-1-1|2015-01-01 06:11:00|2015-01-01 09:06:00|       On-Time|Delta Air Lines Inc.|San Diego Interna...|    San Diego|          CA|           USA|       32.73356|      -117.18966|      SLC|    Salt Lake City In...|   Salt Lake City|               UT|                USA|            40.78839|           -111.97777|\n",
      "|2015|    1|  1|          4|          DL|         2109|     N550NW|           SAN|                DTW|              07:05|           703|             -2|      13|       716|           259|         233|     214|    1956|     1350|      6|            14:24|       13:56|          -28|       0|        0|             07:03|2015-1-1|2015-01-01 07:03:00|2015-01-01 13:56:00|       On-Time|Delta Air Lines Inc.|San Diego Interna...|    San Diego|          CA|           USA|       32.73356|      -117.18966|      DTW|    Detroit Metropoli...|          Detroit|               MI|                USA|            42.21206|            -83.34884|\n",
      "|2015|    1|  1|          4|          AA|         1482|     N3DUAA|           SFO|                DFW|              07:10|           703|             -7|      16|       719|           210|         214|     185|    1464|     1224|     13|            12:40|       12:37|           -3|       0|        0|             07:03|2015-1-1|2015-01-01 07:03:00|2015-01-01 12:37:00|       On-Time|American Airlines...|San Francisco Int...|San Francisco|          CA|           USA|         37.619|      -122.37484|      DFW|    Dallas/Fort Worth...|Dallas-Fort Worth|               TX|                USA|            32.89595|             -97.0372|\n",
      "|2015|    1|  1|          4|          EV|         5242|     N707EV|           CLE|                LGA|              07:15|           959|            164|      12|      1011|           106|          75|      59|     419|     1110|      4|            09:01|       11:14|          133|       0|        0|             09:59|2015-1-1|2015-01-01 09:59:00|2015-01-01 11:14:00|    Long Delay|Atlantic Southeas...|Cleveland Hopkins...|    Cleveland|          OH|           USA|       41.41089|        -81.8494|      LGA|    LaGuardia Airport...|         New York|               NY|                USA|            40.77724|            -73.87261|\n",
      "|2015|    1|  1|          4|          OO|         4836|     N549CA|           LAS|                SLC|              08:00|           755|             -5|      15|       810|            85|          89|      66|     368|     1016|      8|            10:25|       10:24|           -1|       0|        0|             07:55|2015-1-1|2015-01-01 07:55:00|2015-01-01 10:24:00|       On-Time|Skywest Airlines ...|McCarran Internat...|    Las Vegas|          NV|           USA|       36.08036|      -115.15233|      SLC|    Salt Lake City In...|   Salt Lake City|               UT|                USA|            40.78839|           -111.97777|\n",
      "+----+-----+---+-----------+------------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+------------------+--------+-------------------+-------------------+--------------+--------------------+--------------------+-------------+------------+--------------+---------------+----------------+---------+------------------------+-----------------+-----------------+-------------------+--------------------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "flights_enriched_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üõ†Ô∏è  **Dropping the columns not needed for our analysis**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets drop the columns not needed for our analysis\n",
    "\n",
    "flights_enriched_df = flights_enriched_df.drop(\"DAY\", \"DEPARTURE_TIME\", \"IATA_CODE\" , \"FLIGHT_NUMBER\", \"TAIL_NUMBER\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we got some nulls in the data, lets drop them\n",
    "flights_enriched_df = flights_enriched_df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 209:>                                                      (0 + 12) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----------+------------+--------------+-------------------+-------------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+------------------+----+-------------------+-----------------+--------------+------------+-------------------+-----------+------------+--------------+---------------+----------------+------------------------+----------------+-----------------+-------------------+--------------------+---------------------+\n",
      "|YEAR|MONTH|DAY_OF_WEEK|AIRLINE_CODE|ORIGIN_AIRPORT|DESTINATION_AIRPORT|SCHEDULED_DEPARTURE|DEPARTURE_DELAY|TAXI_OUT|WHEELS_OFF|SCHEDULED_TIME|ELAPSED_TIME|AIR_TIME|DISTANCE|WHEELS_ON|TAXI_IN|SCHEDULED_ARRIVAL|ARRIVAL_TIME|ARRIVAL_DELAY|DIVERTED|CANCELLED|DEPARTURE_TIME_STR|DATE|DEPARTURE_DATE_TIME|ARRIVAL_DATE_TIME|DELAY_CATEGORY|AIRLINE_NAME|ORIGIN_AIRPORT_NAME|ORIGIN_CITY|ORIGIN_STATE|ORIGIN_COUNTRY|ORIGIN_LATITUDE|ORIGIN_LONGITUDE|DESTINATION_AIRPORT_NAME|DESTINATION_CITY|DESTINATION_STATE|DESTINATION_COUNTRY|DESTINATION_LATITUDE|DESTINATION_LONGITUDE|\n",
      "+----+-----+-----------+------------+--------------+-------------------+-------------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+------------------+----+-------------------+-----------------+--------------+------------+-------------------+-----------+------------+--------------+---------------+----------------+------------------------+----------------+-----------------+-------------------+--------------------+---------------------+\n",
      "|   0|    0|          0|           0|             0|                  0|                  0|              0|       0|         0|             0|           0|       0|       0|        0|      0|                0|           0|            0|       0|        0|                 0|   0|                  0|                0|             0|           0|                  0|          0|           0|             0|              0|               0|                       0|               0|                0|                  0|                   0|                    0|\n",
      "+----+-----+-----------+------------+--------------+-------------------+-------------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+------------------+----+-------------------+-----------------+--------------+------------+-------------------+-----------+------------+--------------+---------------+----------------+------------------------+----------------+-----------------+-------------------+--------------------+---------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "exprs = [F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in flights_enriched_df.columns]\n",
    "flights_enriched_df.select(exprs).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### üìà Some observations:-\n",
    "\n",
    " * We have successfully joined the dataframes with the airlines and airports data and our final dataframe is ready for analysis named `flights_enriched_df`.\n",
    "\n",
    " * We have also dropped the columns not needed for our analysis.\n",
    " \n",
    " * Brodcast joins are great when we are joining a small dataframe with a large dataframe as it avoid shuffling the data and it is more efficient.\n",
    "\n",
    "* After joining the dataframes we even got some nulls in the data, which we dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üì• **Caching the dataframe**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "<div style=\"width:450px; aspect-ratio:16/9;\">\n",
    "  <img src=\"../img/caching.jpeg\" alt=\"brodcast\" style=\"width:100%; height:auto; border-radius:8px;\">\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[YEAR: int, MONTH: int, DAY_OF_WEEK: int, AIRLINE_CODE: string, ORIGIN_AIRPORT: string, DESTINATION_AIRPORT: string, SCHEDULED_DEPARTURE: string, DEPARTURE_DELAY: int, TAXI_OUT: int, WHEELS_OFF: int, SCHEDULED_TIME: int, ELAPSED_TIME: int, AIR_TIME: int, DISTANCE: int, WHEELS_ON: int, TAXI_IN: int, SCHEDULED_ARRIVAL: string, ARRIVAL_TIME: string, ARRIVAL_DELAY: int, DIVERTED: int, CANCELLED: int, DEPARTURE_TIME_STR: string, DATE: string, DEPARTURE_DATE_TIME: timestamp, ARRIVAL_DATE_TIME: timestamp, DELAY_CATEGORY: string, AIRLINE_NAME: string, ORIGIN_AIRPORT_NAME: string, ORIGIN_CITY: string, ORIGIN_STATE: string, ORIGIN_COUNTRY: string, ORIGIN_LATITUDE: double, ORIGIN_LONGITUDE: double, DESTINATION_AIRPORT_NAME: string, DESTINATION_CITY: string, DESTINATION_STATE: string, DESTINATION_COUNTRY: string, DESTINATION_LATITUDE: double, DESTINATION_LONGITUDE: double]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so this is our final data that we will be using a lot so lets cache it\n",
    "flights_enriched_df.cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 221:==================================================>  (192 + 8) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----------+------------+--------------+-------------------+-------------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+------------------+--------+-------------------+-------------------+--------------+--------------------+--------------------+-------------+------------+--------------+---------------+----------------+------------------------+-----------------+-----------------+-------------------+--------------------+---------------------+\n",
      "|YEAR|MONTH|DAY_OF_WEEK|AIRLINE_CODE|ORIGIN_AIRPORT|DESTINATION_AIRPORT|SCHEDULED_DEPARTURE|DEPARTURE_DELAY|TAXI_OUT|WHEELS_OFF|SCHEDULED_TIME|ELAPSED_TIME|AIR_TIME|DISTANCE|WHEELS_ON|TAXI_IN|SCHEDULED_ARRIVAL|ARRIVAL_TIME|ARRIVAL_DELAY|DIVERTED|CANCELLED|DEPARTURE_TIME_STR|    DATE|DEPARTURE_DATE_TIME|  ARRIVAL_DATE_TIME|DELAY_CATEGORY|        AIRLINE_NAME| ORIGIN_AIRPORT_NAME|  ORIGIN_CITY|ORIGIN_STATE|ORIGIN_COUNTRY|ORIGIN_LATITUDE|ORIGIN_LONGITUDE|DESTINATION_AIRPORT_NAME| DESTINATION_CITY|DESTINATION_STATE|DESTINATION_COUNTRY|DESTINATION_LATITUDE|DESTINATION_LONGITUDE|\n",
      "+----+-----+-----------+------------+--------------+-------------------+-------------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+------------------+--------+-------------------+-------------------+--------------+--------------------+--------------------+-------------+------------+--------------+---------------+----------------+------------------------+-----------------+-----------------+-------------------+--------------------+---------------------+\n",
      "|2015|    1|          4|          DL|           SAN|                SLC|              06:15|             -4|      20|       631|           121|         115|      89|     626|      900|      6|            09:16|       09:06|          -10|       0|        0|             06:11|2015-1-1|2015-01-01 06:11:00|2015-01-01 09:06:00|       On-Time|Delta Air Lines Inc.|San Diego Interna...|    San Diego|          CA|           USA|       32.73356|      -117.18966|    Salt Lake City In...|   Salt Lake City|               UT|                USA|            40.78839|           -111.97777|\n",
      "|2015|    1|          4|          DL|           SAN|                DTW|              07:05|             -2|      13|       716|           259|         233|     214|    1956|     1350|      6|            14:24|       13:56|          -28|       0|        0|             07:03|2015-1-1|2015-01-01 07:03:00|2015-01-01 13:56:00|       On-Time|Delta Air Lines Inc.|San Diego Interna...|    San Diego|          CA|           USA|       32.73356|      -117.18966|    Detroit Metropoli...|          Detroit|               MI|                USA|            42.21206|            -83.34884|\n",
      "|2015|    1|          4|          AA|           SFO|                DFW|              07:10|             -7|      16|       719|           210|         214|     185|    1464|     1224|     13|            12:40|       12:37|           -3|       0|        0|             07:03|2015-1-1|2015-01-01 07:03:00|2015-01-01 12:37:00|       On-Time|American Airlines...|San Francisco Int...|San Francisco|          CA|           USA|         37.619|      -122.37484|    Dallas/Fort Worth...|Dallas-Fort Worth|               TX|                USA|            32.89595|             -97.0372|\n",
      "|2015|    1|          4|          EV|           CLE|                LGA|              07:15|            164|      12|      1011|           106|          75|      59|     419|     1110|      4|            09:01|       11:14|          133|       0|        0|             09:59|2015-1-1|2015-01-01 09:59:00|2015-01-01 11:14:00|    Long Delay|Atlantic Southeas...|Cleveland Hopkins...|    Cleveland|          OH|           USA|       41.41089|        -81.8494|    LaGuardia Airport...|         New York|               NY|                USA|            40.77724|            -73.87261|\n",
      "|2015|    1|          4|          OO|           LAS|                SLC|              08:00|             -5|      15|       810|            85|          89|      66|     368|     1016|      8|            10:25|       10:24|           -1|       0|        0|             07:55|2015-1-1|2015-01-01 07:55:00|2015-01-01 10:24:00|       On-Time|Skywest Airlines ...|McCarran Internat...|    Las Vegas|          NV|           USA|       36.08036|      -115.15233|    Salt Lake City In...|   Salt Lake City|               UT|                USA|            40.78839|           -111.97777|\n",
      "+----+-----+-----------+------------+--------------+-------------------+-------------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+------------------+--------+-------------------+-------------------+--------------+--------------------+--------------------+-------------+------------+--------------+---------------+----------------+------------------------+-----------------+-----------------+-------------------+--------------------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "flights_enriched_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### üí° Some observations:-\n",
    "* Caching the dataframe is great when we are using the same dataframe multiple times in our analysis.\n",
    "* It is great for performance and it is more efficient.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìä **Data Analysis**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<div style=\"width:450px; aspect-ratio:16/9;\">\n",
    "  <img src=\"../img/data_analysis.jpeg\" alt=\"img\" style=\"width:100%; height:auto; border-radius:8px;\">\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### üß© Monthly flight volume and percentage of delayed flights. \n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|MONTH| count|\n",
      "+-----+------+\n",
      "|    1|174523|\n",
      "+-----+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "flights_enriched_df.groupby('MONTH').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|DELAY_CATEGORY|count|\n",
      "+--------------+-----+\n",
      "|  Medium Delay|35211|\n",
      "|    Long Delay|17774|\n",
      "|   Short Delay|37679|\n",
      "|       On-Time|83859|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DELAY_DF = flights_enriched_df.groupby('DELAY_CATEGORY').count()\n",
    "DELAY_DF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+---------------+------------------+\n",
      "|MONTH|total_flights|delayed_flights|delayed_percentage|\n",
      "+-----+-------------+---------------+------------------+\n",
      "|    1|       174523|          90664|51.949599766219926|\n",
      "+-----+-------------+---------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# 1. Define which categories are considered \"delayed\"\n",
    "delayed_categories = [\"Short Delay\", \"Medium Delay\", \"Long Delay\"]\n",
    "\n",
    "# 2. Calculate monthly flight volume and delayed flight count\n",
    "monthly_stats = (\n",
    "    flights_enriched_df\n",
    "    .groupBy(\"MONTH\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"total_flights\"),\n",
    "        F.sum(F.when(F.col(\"DELAY_CATEGORY\").isin(delayed_categories), 1).otherwise(0)).alias(\"delayed_flights\")\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"delayed_percentage\",\n",
    "        (F.col(\"delayed_flights\") / F.col(\"total_flights\") * 100).cast(\"double\")\n",
    "    )\n",
    "    .orderBy(\"MONTH\")\n",
    ")\n",
    "\n",
    "monthly_stats.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### üîó Airline-wise average departure delay and on-time performance.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------+---------------+------------------+\n",
      "|        AIRLINE_NAME|avg_departure_delay|total_flights|on_time_flights|on_time_percentage|\n",
      "+--------------------+-------------------+-------------+---------------+------------------+\n",
      "|Hawaiian Airlines...|  4.897582957804179|         2441|           1170|  47.9311757476444|\n",
      "|Alaska Airlines Inc.|  5.494282334384858|         5072|           3156| 62.22397476340694|\n",
      "|     US Airways Inc.|  9.102912005078156|        12603|           6746|53.526938030627626|\n",
      "|      Virgin America|  9.177145981410607|         1829|           1096| 59.92345544013122|\n",
      "|Delta Air Lines Inc.|  9.938347307387478|        23973|          15517| 64.72698452425647|\n",
      "|     JetBlue Airways| 16.128854229154168|         8335|           4188|50.245950809838035|\n",
      "|Southwest Airline...|  17.60894411947058|        37097|          17181|46.313718090411626|\n",
      "|Atlantic Southeas...|  19.07573298712539|        18486|           8360|  45.2234123120199|\n",
      "|American Airlines...| 19.713819368879218|        16542|           7221|  43.6525208560029|\n",
      "|Skywest Airlines ...|  19.89092137108122|        17767|           7862| 44.25057691225305|\n",
      "|    Spirit Air Lines| 23.474331386412544|         3253|           1300| 39.96311097448509|\n",
      "|United Air Lines ...|  23.96036709721278|        14710|           6504| 44.21481985044188|\n",
      "|Frontier Airlines...|  29.42678300455235|         2636|            873| 33.11836115326252|\n",
      "|American Eagle Ai...| 30.523979957050823|         9779|           2685|27.456795173330605|\n",
      "+--------------------+-------------------+-------------+---------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "airline_performance = (\n",
    "    flights_enriched_df\n",
    "    .groupBy(\"AIRLINE_NAME\")\n",
    "    .agg(\n",
    "        F.avg(\"DEPARTURE_DELAY\").alias(\"avg_departure_delay\"),\n",
    "        F.count(\"*\").alias(\"total_flights\"),\n",
    "        F.sum(F.when(F.col(\"DELAY_CATEGORY\") == \"On-Time\", 1).otherwise(0)).alias(\"on_time_flights\")\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"on_time_percentage\",\n",
    "        (F.col(\"on_time_flights\") / F.col(\"total_flights\") * 100).cast(\"double\")\n",
    "    )\n",
    "    .orderBy(F.asc(\"avg_departure_delay\"))\n",
    ")\n",
    "\n",
    "airline_performance.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### üî¥ Total number of cancellations and their distribution by cancellation reason.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|CANCELLED|cancellation_count|\n",
      "+---------+------------------+\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# - Total number of cancellations and their distribution by cancellation reason.\n",
    "\n",
    "flights_enriched_df.createOrReplaceTempView(\"flights_enriched_df\")\n",
    "\n",
    "result = spark.sql(\"SELECT CANCELLED, COUNT(*) AS cancellation_count FROM flights_enriched_df WHERE CANCELLED = 1 GROUP BY CANCELLED\")\n",
    "\n",
    "result.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üö¶ Which is the busiest airport i.e most flights take-off and landing?\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 247:===============================================>    (363 + 12) / 400]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+\n",
      "|        airport_name|total_flights|\n",
      "+--------------------+-------------+\n",
      "|Hartsfield-Jackso...|        21923|\n",
      "|Dallas/Fort Worth...|        16947|\n",
      "|Chicago O'Hare In...|        16210|\n",
      "|Los Angeles Inter...|        13206|\n",
      "|Denver Internatio...|        13166|\n",
      "|George Bush Inter...|        10287|\n",
      "|Phoenix Sky Harbo...|        10111|\n",
      "|San Francisco Int...|         9822|\n",
      "|McCarran Internat...|         8716|\n",
      "|Orlando Internati...|         7753|\n",
      "+--------------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Combine all take-offs and landings into a single column\n",
    "all_airports = (\n",
    "    flights_enriched_df\n",
    "    .select(F.col(\"ORIGIN_AIRPORT_NAME\").alias(\"airport_name\"))\n",
    "    .union(\n",
    "        flights_enriched_df.select(F.col(\"DESTINATION_AIRPORT_NAME\").alias(\"airport_name\"))\n",
    "    )\n",
    ")\n",
    "\n",
    "# Group by airport and count total flights (take-offs + landings)\n",
    "busiest_airports = (\n",
    "    all_airports\n",
    "    .groupBy(\"airport_name\")\n",
    "    .agg(F.count(\"*\").alias(\"total_flights\"))\n",
    "    .orderBy(F.desc(\"total_flights\"))\n",
    ")\n",
    "\n",
    "busiest_airports.show(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üåÜ Which city has the most flights i.e most flights take-off and landing in that city?\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 252:================================================>   (374 + 12) / 400]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------+\n",
      "|        city_name|total_flights|\n",
      "+-----------------+-------------+\n",
      "|          Atlanta|        21923|\n",
      "|          Chicago|        21025|\n",
      "|Dallas-Fort Worth|        16947|\n",
      "|          Houston|        13747|\n",
      "|      Los Angeles|        13206|\n",
      "|           Denver|        13166|\n",
      "|         New York|        13058|\n",
      "|          Phoenix|        10111|\n",
      "|    San Francisco|         9822|\n",
      "|        Las Vegas|         8716|\n",
      "+-----------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Combine all take-offs and landings into a single column\n",
    "all_cities = (\n",
    "    flights_enriched_df\n",
    "    .select(F.col(\"ORIGIN_CITY\").alias(\"city_name\"))\n",
    "    .union(\n",
    "        flights_enriched_df.select(F.col(\"DESTINATION_CITY\").alias(\"city_name\"))\n",
    "    )\n",
    ")\n",
    "\n",
    "# Group by city and count total flights (take-offs + landings)\n",
    "busiest_cities = (\n",
    "    all_cities\n",
    "    .groupBy(\"city_name\")\n",
    "    .agg(F.count(\"*\").alias(\"total_flights\"))\n",
    "    .orderBy(F.desc(\"total_flights\"))\n",
    ")\n",
    "\n",
    "busiest_cities.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üö® Which airlines has the least number of flight?\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|        AIRLINE_NAME|count|\n",
      "+--------------------+-----+\n",
      "|      Virgin America| 1829|\n",
      "|Hawaiian Airlines...| 2441|\n",
      "|Frontier Airlines...| 2636|\n",
      "|    Spirit Air Lines| 3253|\n",
      "|Alaska Airlines Inc.| 5072|\n",
      "|     JetBlue Airways| 8335|\n",
      "|American Eagle Ai...| 9779|\n",
      "|     US Airways Inc.|12603|\n",
      "|United Air Lines ...|14710|\n",
      "|American Airlines...|16542|\n",
      "|Skywest Airlines ...|17767|\n",
      "|Atlantic Southeas...|18486|\n",
      "|Delta Air Lines Inc.|23973|\n",
      "|Southwest Airline...|37097|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "flights_enriched_df.groupBy(\"AIRLINE_NAME\").count().orderBy(\"count\", ascending=True).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### üß† Some observations:-\n",
    "\n",
    "* As we took a subset of the original data,thats why we have only month 1, we can see that the percentage of delayed flights is 51.94% which is quite high.\n",
    "\n",
    "\n",
    "* From the analysis we can see that Hawaiian Airlines has the least number of delayed flights showing their efficiency.\n",
    "\n",
    "\n",
    "* From the analysis we can see that Hartsfield-Jackson Atlanta International Airport has the most number of flights i.e busiest airport.\n",
    "\n",
    "\n",
    "* We can also see that Atlanta and Chicago city have the most number of flights.\n",
    "\n",
    "\n",
    "* From the analysis we can see that Virgin America has the least number of flights , indicating that it is not a very popular airline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üì§ **Saving to s3 parquet busiest cities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved directly to s3a://dvflightdata/parquet_export_20250511_184028_7d0f3813/ as Parquet.\n"
     ]
    }
   ],
   "source": [
    "from src.upload_csv_to_s3 import save_df_to_s3_parquet\n",
    "save_df_to_s3_parquet(busiest_cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚öîÔ∏è Udf vs native PySpark functions\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "def classify_delay_udf(delay):\n",
    "    if delay is None:\n",
    "        return \"Unknown\"\n",
    "    elif delay <= 0:\n",
    "        return \"On-Time\"\n",
    "    elif delay <= 15:\n",
    "        return \"Short Delay\"\n",
    "    elif delay <= 60:\n",
    "        return \"Medium Delay\"\n",
    "    else:\n",
    "        return \"Long Delay\"\n",
    "\n",
    "# Register the UDF\n",
    "delay_category_udf = udf(classify_delay_udf, StringType())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UDF version took 5.03 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 279:=============================================>           (4 + 1) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Native version took 4.72 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# UDF version\n",
    "start_udf = time.time()\n",
    "df_udf = flights_df.withColumn(\"DELAY_CATEGORY_UDF\", delay_category_udf(flights_df.ARRIVAL_DELAY))\n",
    "df_udf.count()  #  evaluation\n",
    "end_udf = time.time()\n",
    "print(f\"UDF version took {end_udf - start_udf:.2f} seconds\")\n",
    "\n",
    "# Native version\n",
    "start_native = time.time()\n",
    "df_native = flights_df.withColumn(\n",
    "    \"DELAY_CATEGORY_NATIVE\",\n",
    "    F.when(F.col(\"ARRIVAL_DELAY\").isNull(), \"Unknown\")\n",
    "     .when(F.col(\"ARRIVAL_DELAY\") <= 0, \"On-Time\")\n",
    "     .when(F.col(\"ARRIVAL_DELAY\") <= 15, \"Short Delay\")\n",
    "     .when(F.col(\"ARRIVAL_DELAY\") <= 60, \"Medium Delay\")\n",
    "     .otherwise(\"Long Delay\")\n",
    ")\n",
    "df_native.count()  #  evaluation\n",
    "end_native = time.time()\n",
    "print(f\"Native version took {end_native - start_native:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### üóíÔ∏è Some observations:-\n",
    "\n",
    "* Native PySpark functions are generally faster and more scalable than UDFs, especially on large datasets.\n",
    "\n",
    "* Small timing differences on small data or single runs are not significant as in our case.\n",
    "\n",
    "* For production and big data, always prefer native functions when possible.\n",
    "\n",
    "* In my case the native version took 4.72 seconds and UDF version took 5.03 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div align=\"center\">\n",
    "<div style=\"width:100%; aspect-ratio:16/9;\">\n",
    "  <img src=\"../img/safe.png\" alt=\"img\" style=\"width:100%; height:auto; border-radius:8px;\">\n",
    "</div>\n",
    "</div>\n",
    "\n",
    "#### üòäüíó **Thankyou for visiting my project, I hope you liked it.**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
